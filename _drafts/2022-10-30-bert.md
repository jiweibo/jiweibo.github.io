---
layout: post
title:  "bert for tvm"
date:   2022-10-30 20:40:00 +0800
description: tvm
categories: tvm
tags: [tvm]
location: Beijing,China
---


## 获取模型

从transformers中获取bert模型，并导出onnx格式；

```python
from pathlib import Path
from transformers import BertTokenizer, BertModel
import torch
from transformers.onnx import FeaturesManager
import transformers

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertModel.from_pretrained("bert-base-uncased")
feature = "sequence-classification"

model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)
onnx_config = model_onnx_config(model.config)

# inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
# outputs = model(**inputs)
# print(outputs)

onnx_inputs, onnx_outputs = transformers.onnx.export(
    preprocessor=tokenizer,
    model=model,
    config=onnx_config,
    opset=13,
    output=Path("trfs-model.onnx"))
```


## onnxruntime trt 性能


## 使用tvm推理



## References

[1] https://huggingface.co/blog/convert-transformers-to-onnx