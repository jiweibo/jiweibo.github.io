---
layout: post
title:  "bert for tvm"
date:   2022-10-30 20:40:00 +0800
description: tvm
categories: tvm
tags: [tvm]
location: Beijing,China
---


## 获取模型

从transformers中获取bert模型，并导出onnx格式；

```python
from pathlib import Path
from transformers import BertTokenizer, BertModel
import torch
from transformers.onnx import FeaturesManager
import transformers

tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
model = BertModel.from_pretrained("bert-base-uncased")
feature = "sequence-classification"

model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)
onnx_config = model_onnx_config(model.config)

# inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
# outputs = model(**inputs)
# print(outputs)

onnx_inputs, onnx_outputs = transformers.onnx.export(
    preprocessor=tokenizer,
    model=model,
    config=onnx_config,
    opset=13,
    output=Path("trfs-model.onnx"))
```


## onnxruntime trt 性能


## 使用tvm推理

---

### tvm基本使用流程

以下示例代码来自官方文档[[2](https://tvm.apache.org/docs/tutorial/autotvm_relay_x86.html)]。

- 准备模型和数据
```bash
wget https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v2-7.onnx
wget https://s3.amazonaws.com/model-server/inputs/kitten.jpg
```

```python
from PIL import Image
import numpy as np
import onnx
import tvm.relay as relay
import tvm
from tvm.contrib import graph_executor

np.random.seed(0)

resized_image = Image.open('./kitten.jpg').resize((224, 224))
img_data = np.asarray(resized_image).astype('float32')

img_data = np.transpose(img_data, (2, 0, 1))
imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))
imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))
norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev
img_data = np.expand_dims(norm_img_data, axis=0)

onnx_model = onnx.load('./resnet50-v2-7.onnx')

input_name = "data"
shape_dict = {input_name: [1, 3, 224, 224]}

mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)

target = 'llvm'
with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target, params=params)

dev = tvm.device(str(target), 0)
module = graph_executor.GraphModule(lib['default'](dev))

dtype = 'float32'
module.set_input(input_name, img_data)
module.run()
output_shape = (1, 1000)
tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()
print(tvm_output.shape)
```

解析 tvm 中的 Pass，TODO。

解析 tvm 的编译过程，TODO。


## References

[1] https://huggingface.co/blog/convert-transformers-to-onnx

[2] https://tvm.apache.org/docs/tutorial/autotvm_relay_x86.html